{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KLUE self-evaluation",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1MwCB-If7WLju77jE7u7Oe1PFCSx7noNu",
      "authorship_tag": "ABX9TyN3jVMjVipUH9QnW1WhloL8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Koowater/goorm-Magicians/blob/main/KLUE_self_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###KLUE 정답과 편집거리 계산 \n",
        "\n",
        "캐글 제출시 편집거리가 어느정도 나올지 예측"
      ],
      "metadata": {
        "id": "maUJlgyDf6GN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "편집거리 함수"
      ],
      "metadata": {
        "id": "nOzQO3yvitl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit(s1, s2, debug=False):\n",
        "    if len(s1) < len(s2):\n",
        "        return edit(s2, s1, debug)\n",
        "\n",
        "    if len(s2) == 0:\n",
        "        return len(s1)\n",
        "\n",
        "    previous_row = range(len(s2) + 1)\n",
        "    for i, c1 in enumerate(s1):\n",
        "        current_row = [i + 1]\n",
        "        for j, c2 in enumerate(s2):\n",
        "            insertions = previous_row[j + 1] + 1\n",
        "            deletions = current_row[j] + 1\n",
        "            substitutions = previous_row[j] + (c1 != c2)\n",
        "            current_row.append(min(insertions, deletions, substitutions))\n",
        "\n",
        "        if debug:\n",
        "            print(current_row[1:])\n",
        "\n",
        "        previous_row = current_row\n",
        "\n",
        "    return previous_row[-1]"
      ],
      "metadata": {
        "id": "6z3NRvDtimNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KLUE dataset 불러옴"
      ],
      "metadata": {
        "id": "MypCCa06R1FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kl_dataset = KoMRC.load(join(data_dir, 'klue-mrc-v1.1_dev.json'))"
      ],
      "metadata": {
        "id": "bB-zf7OGiEgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean"
      ],
      "metadata": {
        "id": "M0_S25n7iql-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1E7jlMjfevU"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    edit_ds=[]\n",
        "    for idx, data in enumerate(kl_dataset): \n",
        "        if verbose: print(f'질문: {data[\"question\"]}')\n",
        "        tokenized_example = tokenizer(data['question'], \n",
        "                                      data['context'], \n",
        "                                      truncation=\"only_second\",\n",
        "                                      max_length=512,\n",
        "                                      stride=128,   #-#\n",
        "                                      return_overflowing_tokens=True,\n",
        "                                      return_offsets_mapping=True,\n",
        "                                      padding='max_length'\n",
        "                                      )\n",
        "        input_ids, token_type_ids = [\n",
        "            torch.tensor(tokenized_example[key], dtype=torch.long, device=\"cuda\")\n",
        "            for key in (\"input_ids\", \"token_type_ids\")\n",
        "        ]\n",
        "        offset_mapping = tokenized_example['offset_mapping']\n",
        "\n",
        "        start_logits, end_logits = model(input_ids=input_ids, token_type_ids=token_type_ids, return_dict=False)\n",
        "        start_logits = start_logits.cpu()\n",
        "        end_logits = end_logits.cpu()\n",
        "\n",
        "        \n",
        "        if kl_dataset[idx][\"answers\"]==[]: #kl dataset은 정답이 없는 문제가 있음 패스\n",
        "          continue\n",
        "        else:\n",
        "          answer=kl_dataset[idx][\"answers\"][0][\"text\"] \n",
        "          predict = postprocessor.eval(input_ids.cpu(), start_logits, end_logits, data['context'], offset_mapping, max_len=24, verbose=verbose) #-# max_len만 바꿔주세요 40, 20, etc\n",
        "          edit_ds.append(edit(predict, answer))\n",
        "        \n",
        "\n",
        "print(f\"kLUE_edit_distance: {mean(edit_ds):.3f}\") "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###max_len에 따른 편집거리 변화 그래프\n",
        "\n",
        "가장 짧은 편집거리를 내는 max_len을 계산 \n",
        "\n",
        "시간이 오래걸림 원하는 범위만 확인"
      ],
      "metadata": {
        "id": "avm7ow-4klYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verbose=False\n",
        "output_path = join('/content/drive/MyDrive/Colab Notebooks/kaggle', 'split train.csv')\n",
        "x=range(1, 50) #-# 원하는 범위만 좁혀서 볼 것\n",
        "leven=[]\n",
        "rows=[]\n",
        "for i in x:\n",
        "  with torch.no_grad():\n",
        "    edit_ds=[]\n",
        "    for idx, data in enumerate(kl_dataset): #-#\n",
        "        if verbose: print(f'질문: {data[\"question\"]}')\n",
        "        tokenized_example = tokenizer(data['question'], \n",
        "                                      data['context'], \n",
        "                                      truncation=\"only_second\",\n",
        "                                      max_length=512,\n",
        "                                      stride=64, \n",
        "                                      return_overflowing_tokens=True,\n",
        "                                      return_offsets_mapping=True,\n",
        "                                      padding='max_length'\n",
        "                                      )\n",
        "        input_ids, token_type_ids = [\n",
        "            torch.tensor(tokenized_example[key], dtype=torch.long, device=\"cuda\")\n",
        "            for key in (\"input_ids\", \"token_type_ids\")\n",
        "        ]\n",
        "        offset_mapping = tokenized_example['offset_mapping']\n",
        "\n",
        "        start_logits, end_logits = model(input_ids=input_ids, token_type_ids=token_type_ids, return_dict=False)\n",
        "        start_logits = start_logits.cpu()\n",
        "        end_logits = end_logits.cpu()\n",
        "        \n",
        "        if kl_dataset[idx][\"answers\"]==[]:\n",
        "          continue\n",
        "        else:\n",
        "          answer=kl_dataset[idx][\"answers\"][0][\"text\"]\n",
        "          predict = postprocessor.eval(input_ids.cpu(), start_logits, end_logits, data['context'], offset_mapping, max_len=i, verbose=verbose)\n",
        "          edit_ds.append(edit(predict, answer))\n",
        "\n",
        "\n",
        "    leven.append(mean(edit_ds))\n",
        "    min_leven_dist=min(leven)\n",
        "    id=leven.index(min_leven_dist)\n",
        "    rows.append([i, mean(edit_ds)])\n",
        "    print(leven)\n",
        "    print(\"가장 짧은 편집거리:\", min_leven_dist)\n",
        "    print(\"가장 짧은 편집거리를 내는 max_len:\", x[id])\n",
        "\n",
        "df = pd.DataFrame(rows, columns=['max_len', 'edit distance'])\n",
        "df.to_csv(output_path, index=False, sep=',', encoding='utf-8')"
      ],
      "metadata": {
        "id": "7LPYo70WgTYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프"
      ],
      "metadata": {
        "id": "8ya8QlJ0SqU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "# y = leven\n",
        "# plt.plot(x, y)\n",
        "# plt.xlabel(\"max_len\")\n",
        "# plt.ylabel(\"levenshtein distance\")\n",
        "# plt.title(\"kl_dataset\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "jGZaNQSAgive"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}